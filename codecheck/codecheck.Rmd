---
output:
  pdf_document:
    toc: false
    includes:
      in_header: codecheck-preamble.sty
  html_document:
    self_contained: false
    toc: true
    toc_float: false
urlcolor: blue
---

```{r rsetup,eval=TRUE,include=FALSE}
require(codecheck)
require(knitr)
require(rprojroot)
require(yaml)
require(xtable)
require(tibble)
require(readr)
options(width=60)
opts_chunk$set(cache=FALSE)

root = find_root("codecheck.yml")
```

```{r codecheck_logo, echo=FALSE,results='asis'}
latex_codecheck_logo()
```

```{r manifest, eval=TRUE, include=FALSE}
metadata = codecheck_metadata(root)
manifest = metadata$manifest

dest_dir = file.path(root, "codecheck", "outputs")
## Create the outputs directory if missing
if ( !dir.exists(dest_dir) ) {
  dir.create(dest_dir)
}

## get_outputs = function(manifest) {
##   files = sapply(manifest, function(x) x$file)
##   comments = sapply(manifest, function(x) x$comment)
##   sizes = file.size(dest_files)
##   url=sprintf('<a href="%s">%s</a>', dest_files, files)
##   table = cbind(files, comments, sizes, url)
##   table
## }

manifest_df = copy_manifest_files(root, manifest,
                                  dest_dir, keep_full_path=FALSE)
```

---
title: `r paste("CODECHECK certificate", metadata$certificate)`
subtitle: `r codecheck:::as_latex_url(metadata$report)`
---

```{r summary_metadata, echo=FALSE, results='asis'}
latex_summary_of_metadata(metadata)
```

```{r summary_manifest, echo=FALSE, results='asis'}
m = manifest_df[, c("output", "comment", "size")]
names(m) = c("Output", "Comment", "Size (b)")
xt = xtable(m,
            digits=0,
            caption="Summary of output files generated")
print(xt, include.rownames=FALSE, comment=FALSE)
```


\clearpage
# Summary
I was able to reproduce the results (Tables 3,4,5 and A1) from
Report 9.  Given the large size of each simulation, and the number of
simulations, this took significant time (about 24 hours on a
departmental HPC server) to reproduce the findings in Report 9.
Simulations were repeated using the public CovidSim implementation,
first released in April 2020 onto Github, rather than the private code
used to generate the findings in Report 9.  Small variations
(typically a few percent) in the numbers were observed between Report
9 and my runs which are due to several factors:

1. The CovidSim codebase is now deterministic.
2. Slightly different population input files have been used.
3. These results are the average of NR=10 runs, rather than just one
   simulation as used in Report 9.

However, although the absolute values do not match the initial report,
the overall trends are consistent with the original report.  Note also
that my independent run matches runs by the Imperial team as of
2020-05-28.

# CODECHECK notes

## Installation of CovidSim

The public version of CovidSim was cloned from
<https://github.com/mrc-ide/covid-sim>.  For these runs, the master
version from commit [b125307](https://github.com/mrc-ide/covid-sim/commit/b125307e13d0a5226bff78b472b61a51516064e7) (2020-05-27) was used.  This version is
deterministic across all platforms.  This was compiled for local
workstations and for a [departmental HPC resource](https://www.maths.cam.ac.uk/computing/faculty-hpc-system-fawcett).


## Input parameter files

Input parameter files and R scripts were provided by Prof Ferguson and
are now available from
[covid-sim](https://github.com/mrc-ide/covid-sim) in the report9
folder.

## Running the model

Powershell scripts to generate the suppression and mitigation results
were converted to bash and are provided in the codecheck repository.  These
bash scripts generate a list of jobs that can then be executed on a
local machine or submitted as jobs to a cluster.  More details below.

### Initialisation steps

In each of the suppression and mitigation folders, the output from
`runonce.sh` was run to generate two further input files,
*NetworkGB_8T.bin* and *NoInt_R0=2.4.avNE.severity.xls.* These files
were identical in the two folders.

Two folders were then generated to store the results of the batch runs:

```
mkdir GB_suppress_release/mean8
mkdir GB_mitigation_release/MeanT8_NR10a
```

### Batch jobs

The list of jobs to run for each scenario was generated from the bash
scripts
[GB_suppress_release/batch.sh](https://github.com/codecheckers/covid-report9/blob/master/GB_suppress_release/batch.sh)
and
[GB_mitigation_release/batch.sh](https://github.com/codecheckers/covid-report9/tree/master/GB_mitigation_release/batch.sh).  These generated two job lists: 
[GB_suppress_release/batch-jobs.txt](https://github.com/codecheckers/covid-report9/blob/master/GB_suppress_release/batch-jobs.txt)
and
[GB_mitigation_release/batch-jobs.txt](https://github.com/codecheckers/covid-report9/blob/master/GB_mitigation_release/batch-jobs.txt)

These jobs took about 3 days on a 64-core workstation, and about 1 day
on a departmental HPC cluster.  To repeat these runs on other
computers will depend on your job submission system.  However on a
linux machine, one simple way to start the jobs (with -j being the
number the number of jobs to run in parallel) is:

```
parallel -j8 < batch-jobs.txt
```


### Analysis

Each run generated a CSV (labelled as an .xls) file in the output
folder.  Two R scripts (both named _summariseSev.r_) provided by Prof
Ferguson was used to summarise these runs into two summary files:
[GB_suppress_release/mean8/stats_contain.csv](<https://github.com/codecheckers/covid-report9/blob/master/GB_suppress_release/mean8/stats_contain.csv>)
and
[GB_mitigation_release/MeanT8_NR10/stats_mitigation.csv](https://github.com/codecheckers/covid-report9/blob/master/GB_mitigation_release/MeanT8_NR10/stats_mitigation.csv).

These files were compared against the values generated by Prof
Ferguson and stored in the Excel spreadsheets with *compare_stats.R*
scripts in each strategy folder.  The results were found to be
identical.  Inserting my results into his Excel spreadsheet generated
the same pivot tables.  I took screenshots of these pivot tables to
include for this report.  The Excel summary spreadsheets are available
in the repository.


## Acknowledgements

I would like to thank Prof Ferguson and colleagues for promptly
answering any queries I had with this reproduction.  Dr Kacper Kornet
at the Faculty of Mathematics, University of Cambridge helped with
installation of CovidSim and job submission scripts for the HPC
cluster.  CODECHECK is financially supported by the Mozilla
foundation.


# Citing this document

Eglen, Stephen J. (2020). CODECHECK Certificate
2020-010. Zenodo. <http://doi.org/10.5281/zenodo.3865491>

Please note that DOIs may take a few hours to register after the
certificate is registered.  A copy of the certificate is available in
at
<https://github.com/codecheckers/covid-report9/blob/master/codecheck/codecheck.pdf>.


# About CODECHECK

This certificate confirms that the codechecker could independently
reproduce the results of a computational analysis given the data and
code from a third party.  A CODECHECK does not check whether the
original computation analysis is correct.  However, as all material
required for the reproduction are freely available by following the
links in this document, the reader can then study for themselves the
code and data.

\setcounter{table}{0}
\setcounter{figure}{0}
\captionsetup[table]{labelformat=addC}
\captionsetup[figure]{labelformat=addC}

\clearpage

```{r, echo=FALSE, fig.cap=manifest_df[1:4,"comment"]}
# TODO turn into a loop 
knitr::include_graphics(manifest_df[1, "dest"])
cat('\n\n')
knitr::include_graphics(manifest_df[2, "dest"])
cat('\n\n')
knitr::include_graphics(manifest_df[3, "dest"])
cat('\n\n')
knitr::include_graphics(manifest_df[4, "dest"])
cat('\n\n')
```

\clearpage
# About this document

This document was created using [R Markdown](https://rmarkdown.rstudio.com/) using the [`codecheck`](https://github.com/codecheckers/codecheck) R package.
`make codecheck.pdf` will regenerate the report file.

```{r}
sessionInfo()
```

```{r, include=FALSE, eval=FALSE}
# render this document in RStudio
rmarkdown::render("codecheck.Rmd", output_format = "pdf_document") 
```
